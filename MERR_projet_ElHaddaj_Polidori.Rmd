---
title: 'MRR : Projet'
author: "Lina EL HADDAJ & Ania POLIDORI"
date: '2023-12-10'
output:
  pdf_document:
    fig_caption: yes
  word_document: default
  html_document: default
fontsize: 10pt

---

```{=html}
<style type="text/css">
  body .main-container{
   max-width: 1100px !important;
   width: 1100px !important;
  }
  body {
    max-width: 1100px !important;
    margin = auto;
    padding: 5em;
  }
  body, td{
    font-size: 2em;
  }
  code.r{
    font-size: 1em;
  }
  pre{
    font-size: 1em;
    color: #191970;
  }
</style>
```
[**Remarque : accorder les bons facteurs (on a des chiffres mais c'est pas des numeric, pas d'itération --\> les définir correctement)**]{.underline}

```{r setup, include=FALSE}
rm(list = ls())
set.seed(200)
library(corrplot)
library(ggplot2)
library(dplyr)
library(glmnet)
library(GGally)
library(ROCR)
library(rpart)
library(rpart.plot)
```

```{r}
data <- read.csv(file = "data.csv", sep = ';', header = TRUE)

# remise au bon format des variables à facteurs
data <- data %>% mutate_at(vars(Marital.status,
                                Application.mode,
                                Application.order,
                                Course,
                                Daytime.evening.attendance.,
                                Previous.qualification, 
                                Nacionality,
                                Mother.s.qualification,
                                Father.s.qualification,
                                Mother.s.occupation,
                                Father.s.occupation,
                                Displaced,
                                Educational.special.needs,
                                Debtor,
                                Tuition.fees.up.to.date, 
                                Gender,
                                Scholarship.holder,
                                International, 
                                Target
                                ), as.factor) 

# changement des noms des facteurs du genre (pour que ce soit plus intuitif dans les analyses)
data$Gender <- factor(data$Gender, labels=c("F", "M"))

# création de la nouvelle variable cible
data$Ybin <- factor(ifelse(data$Target == "Graduate", 1, 0))

```


# Introduction

Nous avons un jeu de données composé d'**étudiants qui suivent différents cursus universitaires**. 

Dans celui-ci, de nombreuses informations sur l'étudiant au moment de son arrivée dans son cursus ainsi que des sur ses performances académiques aux premier et second semestres sont connues. 

Grâce à toutes ces informations récoltées, nous allons tenter de répondre à la problématique suivante : 

**Comment utiliser les caractéristiques démographiques, académiques et socio-économiques des étudiants pour prédire avec précision les abandons d'étudiants et les réussites académiques dans un contexte éducatif donné, à un stade tôt de leur chemin académique ?**


La variable cible choisie pour notre analyse est dérivée de la variable `Target`, qui représente le résultat académique des étudiants à la fin de la durée normale du cursus. Cette variable est formulée comme une tâche de classification à trois catégories, distinguant entre les étudiants qui ont abandonné (`dropout`), ceux qui sont inscrits (`enrolled`), et ceux qui ont obtenu leur diplôme (`graduate`).

Afin de simplifier la tâche de prédiction, nous avons créé une variable binaire, `Ybin`, où les étudiants diplômés sont représentés par 1, et les étudiants inscrits ou ayant abandonné par 0. Cette approche nous permet de concentrer notre modèle sur la prédiction de la réussite académique à la fin de la durée normale du cursus, en distinguant de manière binaire entre les étudiants qui obtiennent leur diplôme et ceux qui n'atteignent pas cet objectif, simplifiant ainsi la complexité de la tâche de classification initiale à trois catégories.


Dans une première partie (*cf. rendu 1*), nous avons effectué une étude préliminaire de nos données. Grâce à celle-ci, nous avons pu observer de la corrélation entre certaines de nos variables explicatives, ainsi qu'un lien probable entre certaines de nos variables explicatives et notre variable cible. On va donc modéliser nos données pour tenter d'expliquer et prédire au mieux notre variable cible. 


# Modèle complet

Dans un premier temps, notre variable cible étant maintenant une variable binaire, nous allons effectuer un modèle logistique complet, c'est-à-dire prenant en compte toutes les variables du jeu de données. Cette modélisation nous permettra déjà de savoir si au moins une des variables est significative dans notre modèle, et donc s'il est pertinent de tenter de modéliser la variable cible avec au moins une de ces variables prédictives. 

```{r}
# on retire la variable Target pour ne pas avoir de conflit avec notre nouvelle variable cible
data <- data %>% select(-Target)

# modèle complet 
mod_log <- glm(Ybin ~ . , data, family = "binomial")
summary(mod_log)
```

Plusieurs des variables présentes dans ce modèle ont une p-value < $\alpha = 5\%$ , tels que `Curricular.units.2nd.sem..approved.` ou `Tuition.fees.up.to.date`, les analyses ont donc pu être continuées. 

Mais ce modèle affiche un message permettant de comprendre qu'il y a des problèmes de convergence dans le modèle ce qui va entraîner des problèmes dans le calcul des coefficients. 4 des coefficients n'ont pas pu être définis à cause de singularités, et d'autres affichent des coefficients NA. 

Mais il va quand même être possible d'effectuer des modèles logistiques à l'aide d'autres méthodes. 


# Echantillonnage 

Avant de modéliser les données, le jeu de données a du être découpé aléatoirement en 2 échantillons : un échantillon apprentissage (train) avec $70\%$ du jeu de données initial et un échantillon test avec $30\%$ du jeu de données initial. Cela permettra d'effectuer la modélisation sur l'échantillon d'apprentissage et ensuite de tester ce modèle et effectuer des prédictions sur l'échantillon test qui ne sera pas encore touché.

```{r}
# indices aléatoires pour split le dataset
indices <- sample(1:nrow(data), size = floor(0.70 * nrow(data)))

# échantillon train
train_set <- data[indices,]

#échantillon test
test_set <- data[-indices,]
```

Il a fallu vérifier que le jeu de données a été découpé de façon assez uniforme sur la variable cible afin de ne pas se retrouver avec un manque de données pour créer les modèles. 

```{r}
# summary pour voir les répartitions de toutes les variables
# summary(train_set)
# summary(test_set)
```

```{r}
# proportions de la variable cible dans les deux nouveaux jeux de données
# pour l'échantillon train
round(prop.table(table(train_set$Ybin)) * 100, 2)
# pour l'échantillon test
round(prop.table(table(test_set$Ybin)) * 100, 2)
```


# Modélisation

Afin de trouver un modèle permettant de prédire au mieux notre variable cible, nous allons effectuer deux types de modélisations différentes : la régression logistique pénalisée RIDGE ($\ell_2$) et la régression logistique pénalisée LASSO ($\ell_1$).  

Avec la régression logistique, on peut rencontrer des problèmes de sur-entraînement (*overfitting*) et de colinéarité entre les variables explicatives. 

C'est pour cela que l'on va faire les modèles RIDGE et LASSO : ce sont des régressions qui vont pénaliser les coefficients afin d'avoir un compromis acceptable entre la performance du modèle et la pénalisation des coefficients, en minimisant l'erreur de prédiction tout en homogéninisant les valeurs des paramètres.  

Dans les méthodes de régression pénalisées, $\lambda$ représente l'hyperparamètre clé utilisé pour régulariser les modèles. 

En somme, $\lambda$ reste un outil clé dans la boîte à outils de la régularisation, mais son application dépend du modèle et de ses caractéristiques spécifiques, justifiant son utilisation dans des contextes comme la régression RIDGE et LASSO, mais pas nécessairement dans tous les types de modélisation, notamment la modélisation logistique classique.

Pour LASSO, $\lambda$ favorise la parcimonie, forçant certains coefficients à zéro pour une sélection automatique de variables. 

RIDGE ne va pas vraiment servir à faire de la sélection de variables, mais plutôt à enlever la multi colinéarité des variables.

Contrairement à RIDGE, qui prévient le sur-ajustement en restreignant les coefficients, LASSO offre une solution plus épurée

Dans la modélisation logistique, l'utilisation de $\lambda$ n'est pas courante. 
Les régularisations se font souvent via d'autres mécanismes, comme la pénalité Elastic Net, rendant $\lambda$ spécifique aux approches RIDGE et LASSO.


Les pénalités étant définies en terme de valeurs numériques des coefficients, on va devoir transformer toutes nos variables factorielles (sauf la variable cible) en variables binaires. 

```{r}
# jeu train et test avec toutes les variables factorielles transformées en binaire
# sans la variable cible
x_train <- model.matrix(Ybin ~ . -1 , data = train_set)
x_test <- model.matrix(Ybin ~ . -1 , data = test_set)
```


```{r}
# ajustement du modèle ridge
mod_ridge <- glmnet(x = x_train , y = train_set$Ybin, family = "binomial", alpha = 0)

# ajustement du modèle lasso 
mod_lasso <- glmnet(x = x_train, y = train_set$Ybin, family = "binomial", alpha = 1)

# pour avoir les coefficients de chaque variable par régression
# pour chacun des 100 lambdas pris
## coef.glmnet(mod_ridge)
## coef.glmnet(mod_lasso)
```

En effectuant ces deux régressions avec la commande `glmnet`, un objet en ressort avec plusieurs informations. La valeur de $\lambda$ n'ayant pas été spécifiée, cet objet va contenir 100 valeurs de $\lambda$ différentes. Pour chacun de ces $\lambda$, il y aura les coefficients associés après la pénalisation. 

```{r}
# graphiques des coefficients en fonction des log des lambdas
par(mfrow = c(1,2))
plot(mod_ridge, xvar = "lambda", main = "RIDGE", cex.main = 0.8)
plot(mod_lasso, xvar = "lambda", main = "LASSO", cex.main = 0.8)
```

Les valeurs des $log(\lambda)$ prises dans les modélisations ne sont pas les mêmes : celles utilisées dans la modélisation RIDGE sont en générales plus grandes que celles prises dans la modélisation LASSO. Mais ce qui en ressort pour les 2 modélisations est que plus le $\lambda$ pris est grand, plus les coefficients ont tendance à avoir une valeur nulle. C'est une des **particularités** du paramètre $\lambda$ : plus il est grand, moins il y aura de coefficients. Mais ce qui change de RIDGE à LASSO et qui est visible à travers ces deux graphiques est que les coefficients RIDGE vont converger vers 0 tous à peu près au même $\lambda$ quand il devient très grand, tandis que les coefficients LASSO vont converger vers 0 pour n'importe quel $\lambda$ même s'ils vont presque tous être nuls quand le $\lambda$ est élevé. 

Mais afin d'avoir un modèle pénalisant permettant quand même d'avoir un bon pouvoir prédictif, il faut trouver le **meilleur lambda**. Il est donc nécessaire de faire de la validation croisée. 


## Validation croisée

La validation croisée va permettre de partitionner les données en plusieurs sous-ensembles grâce à la méthode des **k-folds**. Cette méthode divise les données en plis (*folds*) de taille égale. On utilisera les données d'apprentissage pour cela. 

Pour chaque pli, la validation croisée va ajuster le modèle sur les *k-1* plis restants (*ensemble d'entraînement*) et évalué sur le pli retenu (*ensemble de validation*). Ce processus est répété *k* fois, chaque pli servant une fois comme ensemble de validation. 

La validation croisée va permettre de trouver le $\lambda$ optimal, cest-à-dire le $\lambda$ qui maximise les performances moyennes sur les ensembles de validation, c'est à dire sur tous les plis.

Avec la commande `cv.glmnet`, le $\lambda$ choisi est celui qui minimise la déviance binomiale. 
**déviance binomiale à expliquer**




