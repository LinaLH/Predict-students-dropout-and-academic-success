---
title: 'MRR : Projet'
author: "Lina EL HADDAJ & Ania POLIDORI"
date: '2023-12-10'
output:
  pdf_document:
    fig_caption: yes
  word_document: default
  html_document: default
fontsize: 10pt

---

```{=html}
<style type="text/css">
  body .main-container{
   max-width: 1100px !important;
   width: 1100px !important;
  }
  body {
    max-width: 1100px !important;
    margin = auto;
    padding: 5em;
  }
  body, td{
    font-size: 2em;
  }
  code.r{
    font-size: 1em;
  }
  pre{
    font-size: 1em;
    color: #191970;
  }
</style>
```
[**Remarque : accorder les bons facteurs (on a des chiffres mais c'est pas des numeric, pas d'itération --\> les définir correctement)**]{.underline}

```{r setup, include=FALSE}
rm(list = ls())
set.seed(200)
library(corrplot)
library(ggplot2)
library(dplyr)
library(glmnet)
library(GGally)
library(ROCR)
library(rpart)
library(rpart.plot)
```

```{r}
data <- read.csv(file = "data.csv", sep = ';', header = TRUE)

# remise au bon format des variables à facteurs
data <- data %>% mutate_at(vars(Marital.status,
                                Application.mode,
                                Application.order,
                                Course,
                                Daytime.evening.attendance.,
                                Previous.qualification, 
                                Nacionality,
                                Mother.s.qualification,
                                Father.s.qualification,
                                Mother.s.occupation,
                                Father.s.occupation,
                                Displaced,
                                Educational.special.needs,
                                Debtor,
                                Tuition.fees.up.to.date, 
                                Gender,
                                Scholarship.holder,
                                International, 
                                Target
                                ), as.factor) 

# changement des noms des facteurs du genre (pour que ce soit plus intuitif dans les analyses)
data$Gender <- factor(data$Gender, labels=c("F", "M"))

# création de la nouvelle variable cible
data$Ybin <- factor(ifelse(data$Target == "Graduate", 1, 0))

```


# Introduction

Nous avons un jeu de données composé d'**étudiants qui suivent différents cursus universitaires**. 

Dans celui-ci, de nombreuses informations sur l'étudiant au moment de son arrivée dans son cursus ainsi que des sur ses performances académiques aux premier et second semestres sont connues. 

Grâce à toutes ces informations récoltées, nous allons tenter de répondre à la problématique suivante : 

**Comment utiliser les caractéristiques démographiques, académiques et socio-économiques des étudiants pour prédire avec précision les abandons d'étudiants et les réussites académiques dans un contexte éducatif donné, à un stade tôt de leur chemin académique ?**


La variable cible choisie pour notre analyse est dérivée de la variable `Target`, qui représente le résultat académique des étudiants à la fin de la durée normale du cursus. Cette variable est formulée comme une tâche de classification à trois catégories, distinguant entre les étudiants qui ont abandonné (`dropout`), ceux qui sont inscrits (`enrolled`), et ceux qui ont obtenu leur diplôme (`graduate`).

Afin de simplifier la tâche de prédiction, nous avons créé une variable binaire, `Ybin`, où les étudiants diplômés sont représentés par 1, et les étudiants inscrits ou ayant abandonné par 0. Cette approche nous permet de concentrer notre modèle sur la prédiction de la réussite académique à la fin de la durée normale du cursus, en distinguant de manière binaire entre les étudiants qui obtiennent leur diplôme et ceux qui n'atteignent pas cet objectif, simplifiant ainsi la complexité de la tâche de classification initiale à trois catégories.


Dans une première partie (*cf. rendu 1*), nous avons effectué une étude préliminaire de nos données. Grâce à celle-ci, nous avons pu observer de la corrélation entre certaines de nos variables explicatives, ainsi qu'un lien probable entre certaines de nos variables explicatives et notre variable cible. On va donc modéliser nos données pour tenter d'expliquer et prédire au mieux notre variable cible. 


# Modèle complet

Dans un premier temps, notre variable cible étant maintenant une variable binaire, nous allons effectuer un modèle logistique complet, c'est-à-dire prenant en compte toutes les variables du jeu de données. Cette modélisation nous permettra déjà de savoir si au moins une des variables est significative dans notre modèle, et donc s'il est pertinent de tenter de modéliser la variable cible avec au moins une de ces variables prédictives. 

```{r}
# on retire la variable Target pour ne pas avoir de conflit avec notre nouvelle variable cible
data <- data %>% select(-Target)

# modèle complet 
mod_log <- glm(Ybin ~ . , data, family = "binomial")
summary(mod_log)
```

Plusieurs des variables présentes dans ce modèle ont une p-value < $\alpha = 5\%$ , tels que `Curricular.units.2nd.sem..approved.` ou `Tuition.fees.up.to.date`, les analyses ont donc pu être continuées. 

Mais ce modèle affiche un message permettant de comprendre qu'il y a des problèmes de convergence dans le modèle ce qui va entraîner des problèmes dans le calcul des coefficients. 4 des coefficients n'ont pas pu être définis à cause de singularités, et d'autres affichent des coefficients NA. 

Mais il va quand même être possible d'effectuer des modèles logistiques à l'aide d'autres méthodes. 


# Echantillonnage 

Avant de modéliser les données, le jeu de données a du être découpé aléatoirement en 2 échantillons : un échantillon apprentissage (train) avec $70\%$ du jeu de données initial et un échantillon test avec $30\%$ du jeu de données initial. Cela permettra d'effectuer la modélisation sur l'échantillon d'apprentissage et ensuite de tester ce modèle et effectuer des prédictions sur l'échantillon test qui ne sera pas encore touché.

```{r}
# indices aléatoires pour split le dataset
indices <- sample(1:nrow(data), size = floor(0.70 * nrow(data)))

# échantillon train
train_set <- data[indices,]

#échantillon test
test_set <- data[-indices,]
```

Il a fallu vérifier que le jeu de données a été découpé de façon assez uniforme sur la variable cible afin de ne pas se retrouver avec un manque de données pour créer les modèles. 

```{r}
# summary pour voir les répartitions de toutes les variables
# summary(train_set)
# summary(test_set)
```

```{r}
# proportions de la variable cible dans les deux nouveaux jeux de données
# pour l'échantillon train
round(prop.table(table(train_set$Ybin)) * 100, 2)
# pour l'échantillon test
round(prop.table(table(test_set$Ybin)) * 100, 2)
```


# Modélisation

Afin de trouver un modèle permettant de prédire au mieux notre variable cible, nous allons effectuer deux types de modélisations différentes : la régression logistique pénalisée RIDGE ($\ell_2$) et la régression logistique pénalisée LASSO ($\ell_1$).  

Avec la régression logistique, on peut rencontrer des problèmes de sur-entraînement (*overfitting*) et de colinéarité entre les variables explicatives. 

C'est pour cela que l'on va faire les modèles RIDGE et LASSO : ce sont des régressions qui vont pénaliser les coefficients afin d'avoir un compromis acceptable entre la performance du modèle et la pénalisation des coefficients, en minimisant l'erreur de prédiction tout en homogéninisant les valeurs des paramètres.  

Dans les méthodes de régression pénalisées, $\lambda$ représente l'hyperparamètre clé utilisé pour régulariser les modèles. 

En somme, $\lambda$ reste un outil clé dans la boîte à outils de la régularisation, mais son application dépend du modèle et de ses caractéristiques spécifiques, justifiant son utilisation dans des contextes comme la régression RIDGE et LASSO, mais pas nécessairement dans tous les types de modélisation, notamment la modélisation logistique classique.

Pour LASSO, $\lambda$ favorise la parcimonie, forçant certains coefficients à zéro pour une sélection automatique de variables. 

RIDGE ne va pas vraiment servir à faire de la sélection de variables, mais plutôt à enlever la multi colinéarité des variables.

Contrairement à RIDGE, qui prévient le sur-ajustement en restreignant les coefficients, LASSO offre une solution plus épurée

Dans la modélisation logistique, l'utilisation de $\lambda$ n'est pas courante. 
Les régularisations se font souvent via d'autres mécanismes, comme la pénalité Elastic Net, rendant $\lambda$ spécifique aux approches RIDGE et LASSO.


Les pénalités étant définies en terme de valeurs numériques des coefficients, on va devoir transformer toutes nos variables factorielles (sauf la variable cible) en variables binaires. 

```{r}
# jeu train et test avec toutes les variables factorielles transformées en binaire
# sans la variable cible
x_train <- model.matrix(Ybin ~ . -1 , data = train_set)
x_test <- model.matrix(Ybin ~ . -1 , data = test_set)
```


```{r}
# ajustement du modèle ridge
mod_ridge <- glmnet(x = x_train , y = train_set$Ybin, family = "binomial", alpha = 0)

# ajustement du modèle lasso 
mod_lasso <- glmnet(x = x_train, y = train_set$Ybin, family = "binomial", alpha = 1)

# pour avoir les coefficients de chaque variable par régression
# pour chacun des 100 lambdas pris
## coef.glmnet(mod_ridge)
## coef.glmnet(mod_lasso)
```

En effectuant ces deux régressions avec la commande `glmnet`, un objet en ressort avec plusieurs informations. La valeur de $\lambda$ n'ayant pas été spécifiée, cet objet va contenir 100 valeurs de $\lambda$ différentes. Pour chacun de ces $\lambda$, il y aura les coefficients associés après la pénalisation. 

```{r}
# graphiques des coefficients en fonction des log des lambdas
par(mfrow = c(1,2))
plot(mod_ridge, xvar = "lambda", main = "RIDGE", cex.main = 0.8)
plot(mod_lasso, xvar = "lambda", main = "LASSO", cex.main = 0.8)
```

Les valeurs des $log(\lambda)$ prises dans les modélisations ne sont pas les mêmes : celles utilisées dans la modélisation RIDGE sont en générales plus grandes que celles prises dans la modélisation LASSO. Mais ce qui en ressort pour les 2 modélisations est que plus le $\lambda$ pris est grand, plus les coefficients ont tendance à avoir une valeur nulle. C'est une des **particularités** du paramètre $\lambda$ : plus il est grand, moins il y aura de coefficients. Mais ce qui change de RIDGE à LASSO et qui est visible à travers ces deux graphiques est que les coefficients RIDGE vont converger vers 0 tous à peu près au même $\lambda$ quand il devient très grand, tandis que les coefficients LASSO vont converger vers 0 pour n'importe quel $\lambda$ même s'ils vont presque tous être nuls quand le $\lambda$ est élevé. 

Mais afin d'avoir un modèle pénalisant permettant quand même d'avoir un bon pouvoir prédictif, il faut trouver le **meilleur lambda**. Il est donc nécessaire de faire de la validation croisée. 


## Validation croisée

La validation croisée va permettre de partitionner les données en plusieurs sous-ensembles grâce à la méthode des **k-folds**. Cette méthode divise les données en plis (*folds*) de taille égale. On utilisera les données d'apprentissage pour cela. 

Pour chaque pli, la validation croisée va ajuster le modèle sur les *k-1* plis restants (*ensemble d'entraînement*) et évalué sur le pli retenu (*ensemble de validation*). Ce processus est répété *k* fois, chaque pli servant une fois comme ensemble de validation. 

La validation croisée va permettre de trouver le $\lambda$ optimal, cest-à-dire le $\lambda$ qui maximise les performances moyennes sur les ensembles de validation, c'est à dire sur tous les plis.

Avec la commande `cv.glmnet`, le $\lambda$ choisi est celui qui minimise la déviance binomiale. 
C'est une mesure du **mauvais ajustement** du modèle par rapport aux données et une déviance basse pour un modèle logistique indique un bon ajustement du modèle aux données. 

$$D = -2 \times \ell(\hat{\beta})$$ avec $\ell(\hat{\beta})$ la log-vraisemblance sur notre modèle avec les coefficients $\hat{\beta}$. 

```{r}
# on prend 10 k folds, le nombre de folds par défaut 

# cross validation ridge 
cv_ridge <- cv.glmnet(x = x_train, y = train_set$Ybin, family = "binomial", alpha = 0)
# lambda optimal ridge
best_lambda_ridge <- cv_ridge$lambda.min
cat("Lambda optimal ridge :", best_lambda_ridge, "\n")

# cross validation lasso 
cv_lasso <- cv.glmnet(x = x_train, y = train_set$Ybin, family = "binomial", alpha = 1)

# lambda optimal lasso 
best_lambda_lasso <- cv_lasso$lambda.min
cat("Lambda optimal lasso :", best_lambda_lasso, "\n")

# graphiques déviance binomiale en fonction des log lambda
# droite pointillé bleue correspond au lambda optimal

par(mfrow = c(1,2))
# pour la cross validation ridge
plot(cv_ridge)
abline(v = log(best_lambda_ridge), col = "blue", lty = 2, lwd = 2) 
# pour la cross validation lasso 
plot(cv_lasso)
abline(v = log(best_lambda_lasso), col = "blue", lty = 2, lwd = 2)
```

Il s'agit d'un graphique représentant tous les $\lambda$ qui ont été testés avec notre cross validation, en affichant leur log, par rapport à la déviance binomiale. 

Il s'agit de graphiques représentant tous les $\lambda$ qui ont été testés avec la cross validation, en affichant leur log, par rapport à la déviance binomiale. 





# Éxtension de l'étude

Malgré les diverses options d'extension possibles pour notre étude de jeu de données, nous avons délibérément choisi d'explorer une approche différente en adoptant un arbre de classification plutôt que d'opter pour un modèle de régression Elastic Net ou un classificateur k plus proches voisins (k-NN). Cette décision repose sur plusieurs considérations clés :

1.  **Interprétabilité :** Les arbres de classification se distinguent par leur facilité d'interprétation et de visualisation. Leur logique sous-jacente est rendue transparente grâce à des règles de décision simples.

2.  **Non-linéarité :** Les arbres sont capables de saisir des relations non linéaires entre les caractéristiques et la variable cible sans nécessiter une spécification explicite de la forme fonctionnelle.

3.  **Adaptabilité :** Les arbres peuvent traiter efficacement des jeux de données mixtes, comprenant à la fois des caractéristiques catégorielles et numériques, sans nécessiter un prétraitement intensif.

4.  **Robustesse aux valeurs aberrantes :** Comparativement à certains modèles linéaires, les arbres de classification démontrent une relative robustesse face aux valeurs aberrantes.

5.  **Découverte de quelque chose de différent :** En plus des considérations techniques, notre choix reflète également un désir d'exploration et de découverte dans le cadre de notre projet, et l'opportunité de tirer parti des particularités de notre ensemble de données.

```{r}
# Choix des variables pertinentes
selected_vars <- c("Previous.qualification", "Admission.grade", "Debtor", "Mother.s.occupation")

# Création d'un sous-ensemble avec les variables sélectionnées
subset_data <- data[, c(selected_vars, "Ybin")]

# Construction de l'arbre de classification
tree_model <- rpart(Ybin ~ ., data = subset_data, method = "class")

# Visualisation de l'arbre avec des informations détaillées
rpart.plot(tree_model, extra = 101, under = TRUE, type = 2, fallen.leaves = TRUE)
```

```{r}
summary(tree_model)
```

1.  **Variables importantes :**

    -   La variable la plus importante est "Debtor", contribuant à 55 % de l'importance globale. Cela suggère que le fait d'avoir des dettes a un impact significatif sur la prédiction de la variable cible "Ybin" et donc sur la diplomation des étudiants.
    -   Ensuite, "Admission.grade" contribue à 22 %, ce qui indique que les notes d'admission sont également un facteur crucial dans la prise de décision.
    -   "Mother.s.occupation" contribue à 15 %, ce qui suggère que le métier de la mère de l'étudiant joue un rôle important dans la prédiction.
    -   "Previous.qualification" contribue à 7 %, indiquant que le niveau d'éducation précédent a une influence moindre mais non négligeable.

2.  **Nœuds de décision :**

    -   Le nœud 3 (à gauche du nœud principal) utilise principalement la variable "Admission.grade" pour décider de la classification.

    -   Le nœud 7 (à droite du nœud principal) utilise la variable "Mother.s.occupation" pour prendre des décisions.

3.  **Feuilles :**

    -   Les feuilles fournissent des probabilités de classe, par exemple, le nœud 2 (feuille) prédit la classe 0 (non diplomé) avec une probabilité de 0,799, indiquant une forte confiance dans la prédiction.

    -   Le nœud 15 (feuille) prédit la classe 1 (diplômé) avec une probabilité de 0,591.

4.  **Erreurs de classification :**

    -   L'erreur de classification diminue à mesure que l'arbre progresse. Les feuilles ont des erreurs de classification spécifiques, par exemple, le nœud 15 a une erreur de 40,93 %.

5.  **Variables de division :**

    -   L'arbre utilise des variables spécifiques pour diviser les nœuds, telles que "Debtor", "Admission.grade", "Mother.s.occupation", et "Previous.qualification".

Maintenant, examinons les résultats de l'arbre de classification pour chaque variable une à une :

1.  **Debtor (Endetté) :**

    -   **Variable Importance :** 55

    -   L'arbre commence par diviser les données en fonction de la variable "Debtor". La division la plus significative est basée sur le fait d'être endetté ou non.

    -   **Feuille 2 (Endetté) :** Il y a 503 observations dans cette feuille, avec une probabilité de 20% de diplomation (Ybin = 0) et 80% de non-diplomation (Ybin = 1).

    -   **Feuille 3 (Non-endetté) :** Il y a 3921 observations dans cette feuille, avec une probabilité de diplomation de 46% (Ybin = 1) et de non-diplomation de 54% (Ybin = 0).

2.  **Admission.grade (Note d'admission) :**

    -   **Variable Importance :** 22

    -   L'arbre effectue une division supplémentaire en fonction de la note d'admission, en particulier, si la note d'admission est inférieure à 112.25.

    -   **Feuille 6 (Note d'admission \< 112.25) :** Il y a 514 observations dans cette feuille, avec une probabilité de diplomation de 37% (Ybin = 1) et de non-diplomation de 63% (Ybin = 0).

    -   **Feuille 7 (Note d'admission \>= 112.25) :** Il y a 3407 observations dans cette feuille, avec une probabilité de diplomation de 44% (Ybin = 1) et de non-diplomation de 56% (Ybin = 0).

3.  **Mother's Occupation (Profession de la mère) :**

    -   **Variable Importance :** 15

    -   L'arbre effectue une division basée sur la profession de la mère.

    -   **Feuille 14 (Profession de la mère catégorie 0, 1 ou 2) :** Il y a 558 observations dans cette feuille, avec une probabilité de diplomation de 42% (Ybin = 1) et de non-diplomation de 58% (Ybin = 0).

    -   **Feuille 15 (Profession de la mère catégorie 3 à 194) :** Il y a 2849 observations dans cette feuille, avec une probabilité de diplomation de 41% (Ybin = 1) et de non-diplomation de 59% (Ybin = 0).

4.  **Previous qualification (Qualification précédente) :**

    -   **Variable Importance :** 7

    -   L'arbre effectue une division basée sur la qualification précédente.

    -   **Feuille 30 (Qualification précédente catégorie 1 à 15) :** Il y a 345 observations dans cette feuille, avec une probabilité de diplomation de 46% (Ybin = 1) et de non-diplomation de 54% (Ybin = 0).

    -   **Feuille 31 (Qualification précédente catégorie 19 à 43) :** Il y a 2504 observations dans cette feuille, avec une probabilité de diplomation de 39% (Ybin = 1) et de non-diplomation de 61% (Ybin = 0).

Ces résultats fournissent des informations sur la manière dont chaque variable influence la prédiction de diplomation. Par exemple, être endetté semble avoir un impact significatif, tout comme la note d'admission. La profession de la mère et la qualification précédente ont également un certain effet, bien que moins important.

En effet, l'accès à l'éducation supérieure représente souvent un défi financier important pour de nombreuses personnes, avec le coût annuel des études universitaires dans leur pays nécessitant parfois d'importants sacrifices financiers. Dans ce contexte, l'emprunt devient une nécessité incontournable pour certains individus cherchant à poursuivre des études supérieures.

Par ailleurs, un facteur tout aussi crucial, bien que moins prégnant que l'endettement financier, réside dans l'emploi de la mère. Appartenir à une catégorie sociale spécifique en raison de l'emploi des parents peut véritablement servir de levier pour les enfants. Que cet emploi fournisse à la famille des ressources financières supplémentaires ou qu'il requière un niveau d'études élevé, offrant ainsi à l'enfant un modèle de réussite scolaire et des conseils précieux, le statut social des parents exerce un impact significatif sur le parcours éducatif des enfants.

Il convient également de noter que des parents ayant suivi des études poussées peuvent créer un environnement familial plus structuré, avec une attention particulière portée à la scolarité de l'enfant. Cette dynamique familiale peut se traduire par un soutien accru, des attentes éducatives élevées et une sensibilisation accrue à l'importance de la réussite scolaire, contribuant ainsi de manière positive au développement académique de l'enfant.
